#Importam librariile si functiile necesare
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

import keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import load_model
from sklearn.preprocessing import normalize
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score


#Reading the data from the database
data = pd.read_csv("C:\\Users\\drago\\Desktop\\LSTM\\BazaDeDate\\data2.csv", header=None)

#Using every 30th row of data for faster processing
data = data[0::30]
#data.shape
data.head()
#Replacing all boolean values to 1 or 0 and dropping all null/nan values
data.replace({True: 1, False: 0}, inplace=True)
data = data.dropna()
#Reading the names of each sensor using BeautifulSoup 
%pip install beautifulsoup4
%pip install lxml


#Reading from the XML File
from bs4 import BeautifulSoup
with open('OPCUATagsMeaning_SE_Deta.xml', 'r') as file:
    xml_data = file.read()

bs_data = BeautifulSoup(xml_data, "xml")


#Creating the name lists
steps_list = []
items_list = []
sensors_list = []
columns = []

Items = bs_data.find_all('Item')


for item in Items:
    for sensor in item:
        if sensor.name != None:
            sensors_list.append(sensor.name)
            items_list.append(item.get('name'))
            steps_list.append(item.parent.get('name'))
            
            
 #Dropping the invalid columns
invalid_list = [207,208,274,275,325,330,348,349]

for x in invalid_list:
    sensors_list.remove(sensors_list[x])
    items_list.remove(items_list[x])
    steps_list.remove(steps_list[x])
                
        
#Inserting the time column
sensors_list.insert(0,'Time')
items_list.insert(0,'')
steps_list.insert(0,'')

columns.append(sensors_list[0])

for i in range (1,len(sensors_list)):
        columns.append(steps_list[i] + " | " + items_list[i] + " | " +sensors_list[i])
        
    
print("Number of columns: " + str(len(columns)))
#Adding the new header 
header = columns
data.columns = header
data.shape
data.head()
#Replacing the Index of the DataFrame with the Time column
data.index = pd.to_datetime(data["Time"], format='%Y-%m-%d %H:%M:%S')
data.head()
#Adding the Seconds column
data['Seconds'] = data.index.map(pd.Timestamp.timestamp)
data.head()
#Creating the timestamps
day = 60*60*24
year = 365.2425 * day

data['Day sin'] = np.sin(data['Seconds'] * (2* np.pi / day))
data['Day cos'] = np.cos(data['Seconds'] * (2* np.pi / day))
data['Year sin'] = np.sin(data['Seconds'] * (2* np.pi / year))
data['Year cos'] = np.cos(data['Seconds'] * (2* np.pi / year))

data.head()
#Droping the Seconds column and repositioning the timestamps
data = data.drop('Seconds', axis=1)
data = data.drop('Time', axis=1)

columns = data.columns.tolist()
columns = columns[-4:] + columns[:-4]

data = data[columns]

data.head()
#Structuring the data 
def data_to_X_y2(data,step,timesteps=100,outsteps=100):
    
    #Preparing the data
    input_data = data.copy()
    output_data = data.copy()
     
    columns_to_keep = [ 
                        "Step 4 | Reactor Biologic 1 | Debit_Stabilizare_Namol",
                        "Step 4 | Reactor Biologic 1 | Volum_Stabilizare_Namol",
                      ]
    
    columns_to_delete_input = [
        "Step 4 | Reactor Biologic 1 | Pompa_1_Namol_Ore_Functionare",
    ]

    for column in input_data:
        if step not in column and column not in columns_to_keep:
            columns_to_delete_input.append(column)

    input_data.drop(columns=columns_to_delete_input, inplace=True)
    


    columns_to_delete_output = []
    
    for column in output_data:
        if step not in column or ("Stare" not in column and "Avarie" not in column):
            columns_to_delete_output.append(column)

    output_data.drop(columns=columns_to_delete_output, inplace=True)
    
    
    i_columns = input_data.columns
    o_columns = output_data.columns
    
    input_data = input_data.to_numpy()
    output_data = output_data.to_numpy()
    
    #Creating X and y
    X = []
    y = []


    for i in range(len(input_data) - timesteps - outsteps):
        row = [r for r in input_data[i:i+timesteps]]
        X.append(row)

        label = output_data[i + timesteps + outsteps]
        y.append(label)

    X = np.array(X)
    y = np.array(y)

    return X,y,i_columns,o_columns

    
for column in data:
    if "Step 4 | Reactor Biologic 1 |" in column:
        print(column)
timesteps2 = 30
outsteps2 = 30


X2,y2,i_columns2,o_columns2 = data_to_X_y2(data,"Step 4 | Reactor Biologic 1 | Pompa_1_Namol",timesteps=timesteps2,outsteps=outsteps2)
X2.shape , y2.shape
#Coloanele folosite la intrare
print("Intrare:\n", i_columns2.values)

#Coloanele folosite la iesire
print("\nIesire:\n", o_columns2.values)

#Splittind the new data into Train | Test | Validate data
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, shuffle=False)
X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, test_size=0.1, shuffle=False)
X2_train.shape, y2_train.shape, X2_test.shape, y2_test.shape, X2_val.shape, y2_val.shape


#Building the LSTM Model
nr_inputs2 = X2_train.shape[2]
nr_outputs2 = y2_train.shape[1]

'''
model2 = Sequential()
model2.add(InputLayer((timesteps2, nr_inputs2)))
model2.add(LSTM(128, return_sequences=True))
model2.add(Dropout(0.2))
model2.add(LSTM(64))
model2.add(Dense(64, activation='relu'))
model2.add(Dropout(0.2))
model2.add(Dense(8, activation='relu'))
model2.add(Dense(nr_outputs2, activation='linear'))
'''

model2 = Sequential()
model2.add(InputLayer((timesteps2, nr_inputs2)))
model2.add(LSTM(64))
model2.add(Dense(8,'relu'))
model2.add(Dense(nr_outputs2,'linear'))






model2.summary()
#Creating a checkpoint and compilling
#cp = ModelCheckpoint('model2/', save_best_only=True)
model2.compile(loss='mse', optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])
#import absl.logging
#absl.logging.set_verbosity(absl.logging.ERROR)

#Training the model
model2.fit(X2_train,y2_train, validation_data = (X2_val, y2_val),batch_size=32, epochs=10)
predictions2 = model2.predict(X2_test)
actuals2 = y2_test

pred_df2 = pd.DataFrame(predictions2)
actuals_df2 = pd.DataFrame(actuals2)

pred_df2.columns = o_columns2
actuals_df2.columns = o_columns2

for i in o_columns2:
    plt.plot(pred_df2[i], color='red', label='prediction')
    plt.plot(actuals_df2[i], color='green', label='actual')
    plt.title(i)
    plt.legend()
    plt.show()
plt.plot(pred_df2[o_columns2], color='red', label='prediction')
predictions2.min()
data.shape
rounded_predictions = np.around(predictions2).astype(int)

correct_predictions = np.sum(rounded_predictions == actuals2)

accuracy = correct_predictions / len(predictions2)

print("Model accuracy: ", float("{:.5f}".format(accuracy)) * 100, "%")

import numpy as np
from sklearn.metrics import mean_squared_error, r2_score

def calculate_accuracy(actuals, predictions):
    assert len(actuals) == len(predictions)

    r2 = r2_score(actuals, predictions)

    return r2

r2 = calculate_accuracy(actuals2, predictions2)

print("Model accuracy: ", float("{:.5f}".format(r2)) * 100, "%")

from sklearn.metrics import accuracy_score
accuracy_score(actuals2, np.round(predictions2))
model = 1
X_newData = 1
y_newData = 1

contor = 0

model.load_weights('model.h5')

predictions = model.predict(X_newData)

model.layers[contor].trainable = False

model.fit(X_newData, y_newData, epochs=5)

contor = contor + 1

model.save_weights('model.h5')


model2.layers[0].trainable = False  


model2.fit(X_newData, y_newData, epochs=5)

# Step 6: Evaluate Performance
loss, accuracy = model2.evaluate(X2_test, y2_test)
print(f"Loss: {loss}, Accuracy: {accuracy}")
predictions2 = model2.predict(X2_test)
actuals2 = y2_test

pred_df2 = pd.DataFrame(predictions2)
actuals_df2 = pd.DataFrame(actuals2)

pred_df2.columns = o_columns2
actuals_df2.columns = o_columns2

for i in o_columns2:
    plt.plot(pred_df2[i], color='red', label='prediction')
    plt.plot(actuals_df2[i], color='green', label='actual')
    plt.title(i)
    plt.legend()
    plt.show()
